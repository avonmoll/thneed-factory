{
 "metadata": {
  "name": "chasingtails.ipynb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Chasing Tails#\n",
      "So Clicks can be [played out using a thread](http://nbviewer.ipython.org/url/raw.github.com/avonmoll/thneed-factory/master/metplayback_nonblocking.ipynb \"NonBlocking Met Playback\") (via the `Met` class) and [raw audio can be read in and manipulated](http://nbviewer.ipython.org/url/raw.github.com/avonmoll/thneed-factory/master/BeatDetection.ipynb \"Detecting Beats\").  Now the trick is to get this to happen simultaneously.  To make it an even bigger challenge it would be nice to update a plot in real time showing the occurrance of beats versus the metronome clicks.  This is getting at the heart of what [this project]( \"main page not created yet\") is intending to accomplish.  First, however, the following questions must be answered:\n",
      "\n",
      "1. Is the thread implementation for `Met` viable for producing sounds on a regular interval?\n",
      "2. Would a thread implementation be appropriate for some kind of `Listener` class that can read in and manipulate the raw audio in the background?\n",
      "\n",
      "A (possible/naive) concern with going this route of thread-based execution is a breakdown of simultaneity between the two threads.  In order to verify the viability of this method the human aspect will be taken out of the loop"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Hypothesis##\n",
      "If the audio output of the `Met` object is detected by the microphone via the `Listener` object and is shown to be coincident, then this is a viable implementation of simultaneous metronome output / input analaysis. \n",
      "\n",
      "![Crappily drawn MS Paint depiction](/Pics/coincidence.jpg)\n",
      "\n",
      "For posteriety, I will reproduce the `Met` class here so this notebook will stand as a complete entity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyaudio; import time; import wave; import threading\n",
      "\n",
      "class Met(threading.Thread):\n",
      "    def __init__(self, BPM):\n",
      "        super(Met,self).__init__()\n",
      "        self.wf = wave.open('Clicks\\PingLow.wav','rb')\n",
      "        self.CHUNK = 1024\n",
      "        self.frames = []\n",
      "        data = self.wf.readframes(self.CHUNK)\n",
      "        \n",
      "        # store all the bits of the wave file in local memory\n",
      "        while data != '':\n",
      "            self.frames.append(data)\n",
      "            data = self.wf.readframes(self.CHUNK)\n",
      "        \n",
      "        self.BPM = float(BPM)\n",
      "        self.p = pyaudio.PyAudio()\n",
      "        self.s = self.p.open(format=self.p.get_format_from_width(self.wf.getsampwidth()),\n",
      "                channels=self.wf.getnchannels(),\n",
      "                rate=self.wf.getframerate(),\n",
      "                output=True)\n",
      " \n",
      "    def start(self):\n",
      "        super(Met,self).start()\n",
      "    \n",
      "    def run(self): \n",
      "        delt = 60/self.BPM\n",
      "        for i in arange(16+1):\n",
      "            self.click()\n",
      "            time.sleep(delt)\n",
      "        self.s.stop_stream()\n",
      "        self.s.close()\n",
      "        self.wf.close()\n",
      "        self.p.terminate()\n",
      "        \n",
      "    def click(self):\n",
      "        for frame in self.frames:\n",
      "            self.s.write(frame)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##The `Listener` Class##\n",
      "The construction of this class will mainly be based off of code from the [Detecting Beats notebook](http://nbviewer.ipython.org/url/raw.github.com/avonmoll/thneed-factory/master/BeatDetection.ipynb \"Link to Beat Detection notebook\"), but it will be written in a thread fashion, similar to `Met`.  __Somehow this thread is going to have to interact with the foreground in order to communicate the occurrance of a beat__"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}